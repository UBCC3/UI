# Data Model

Data is either stored either in a database (e.g. Postgres ) or in large files on AWS
S3, depending on data size.

## Information in a Database

Users table

  * email - an email address - unique key
  * last login - date/time
  * SSO authentication mechanism - enum : "google", "UBC" etc. (how do we get this information?)
  * login count - how many times the user logged in

Structure table

  * Structure ID - UUID4, unique key. Eg. "978b13f7-4e8b-4944-aba8-647651bdddba"
  * source: enum "uploaded by user", "calculated"
  * created_by_job_id: JobID or NULL
  * username - email address of user that uploaded structure or ran a job that created it
  * structure name - as entered by the user (string)
  * Job IDs - list of job IDs that used this structure

Struture properties table (delete - not needed)
  * Structure ID - UUID4
  * Job ID that calculated the property
  * energy - number
  * molecular orbitals -  if we calculated MOs, the UUID of the job that did the calculaion. Else, NULL
  * vib. freq. - if we calculated v.f., the UUID of the job that did the calculaion. Else, NULL
  * unique key: Structure ID + Job ID

Jobs table

  * job ID - UUID4, unique key. Eg. "978b13f7-4e8b-4944-aba8-647651bdddba"
  * job name - as entered by the user (string)
  * job submission date/time
  * username that submitted the job
  * job start time - first time the job has ran
  * job finish time - last time the jb has ran
  * job status - technical job status : enum: "submitted", "running", "failed", "stopped", "completed". It does not signify that the calculation goal was achieved ( delete this line )
  * job status - technical job status : enum: "submitted", "running", "failed", "cancelled", "completed". It does not signify that the calculation goal was achieved
  * job error message - string of standard error for the job or NULL
  * job tags ( pairs of name=value)
  * job parameter - JSON with all parameters needed for the job. E.g.

         {
                "calculation_type": "scf",
                "package" : "psi4",
                "calculation_goal": [ "energy" "molecular orbitals" ],
               "basis_set": "STO-3G",
               "max_iteration" : 30,
               "use_diis" : true,
                "structures" [UUID, UUID]
           }


## Large data in AWS S3

All information is in one bucket under the main object /ubchemica, with <job-id> replaced by the job UUID.

* /ubchemica/structures/<UUID>.mol - geometry file of the structure in .mol format (do we need different formats?)
* /ubchemica/jobs/<job-id>.json - JSON file containing parsed results from output of job (used for frontend UI)
* /ubchemica/archive/<job-id>.zip - zipped file of complete output from job - this is what user can download
